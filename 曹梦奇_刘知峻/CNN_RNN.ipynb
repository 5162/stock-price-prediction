{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "- This is one of the submitted solutions to Artificial Intelligence Final Project\n",
    "- Team Member: Zhi-jun Liu, Meng-qi Cao\n",
    "\n",
    "This notebook contains the CNN-RNN Solution (**best case** private: 0.00140 | public : 0.00149)\n",
    "\n",
    "We modified learning rate during training dynamically(by observation). With different hyperparameter, you get a flucatuation of about 0.00001.\n",
    "\n",
    "## Prerequisites\n",
    "- python 3.7\n",
    "- Pytorch == 1.0\n",
    "- Pandas == 0.23.4\n",
    "- Numpy == 1.15.4\n",
    "- Tqdm == 4.28.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T21:16:21.517744Z",
     "start_time": "2018-12-28T21:16:21.513987Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tnrange, tqdm, tqdm_notebook, trange\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T21:16:21.596222Z",
     "start_time": "2018-12-28T21:16:21.589589Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "default_cpu_tensor_type = torch.FloatTensor\n",
    "torch.set_default_tensor_type(default_cpu_tensor_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T21:16:21.703273Z",
     "start_time": "2018-12-28T21:16:21.699717Z"
    }
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\")\n",
    "# torch.cuda.set_device(device.index)\n",
    "# default_gpu_tensor_type = torch.cuda.FloatTensor\n",
    "# torch.set_default_tensor_type(default_gpu_tensor_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T21:16:22.080972Z",
     "start_time": "2018-12-28T21:16:22.062597Z"
    }
   },
   "outputs": [],
   "source": [
    "class CSVReader:\n",
    "    dataitems = [\"Volume\", \"BidVolume1\", \"AskVolume1\", \"AskPrice1\", \"MidPrice\"]\n",
    "    def __init__(self, training_set=\"./train_data.csv\", testing_set=\"./test_data.csv\"):\n",
    "        self.Train = pd.read_csv(training_set,\n",
    "                                 index_col=\"Date\",\n",
    "                                 usecols=[\n",
    "                                     \"Date\", \"Time\",\n",
    "                                     \"MidPrice\", \"LastPrice\",\n",
    "                                     \"Volume\", \"BidPrice1\",\n",
    "                                     \"BidVolume1\", \"AskPrice1\",\n",
    "                                     \"AskVolume1\"\n",
    "                                 ])\n",
    "\n",
    "        self.Test = pd.read_csv(testing_set,\n",
    "                                index_col=\"Date\",\n",
    "                                usecols=[\n",
    "                                    \"Date\", \"Time\",\n",
    "                                    \"MidPrice\", \"LastPrice\",\n",
    "                                    \"Volume\", \"BidPrice1\",\n",
    "                                    \"BidVolume1\", \"AskPrice1\",\n",
    "                                    \"AskVolume1\"\n",
    "                                ])\n",
    "\n",
    "\n",
    "        self.Train = self.Train.sort_index()\n",
    "        self.Test = self.Test.sort_index()\n",
    "        def hour(s):\n",
    "            q = [float(i) for i in s.split(\":\")]\n",
    "            return q[0] + q[1] / 60\n",
    "\n",
    "        self.Train[\"Hour\"] = self.Train[\"Time\"].map(hour)\n",
    "\n",
    "        self.Test[\"Hour\"] = self.Test[\"Time\"].map(hour)\n",
    "\n",
    "        TimeStampCount = self.Train[\"Time\"].groupby(\"Date\").count()\n",
    "        TimeStampCount = TimeStampCount.sort_values()\n",
    "\n",
    "        self.TrainDates = self.Train.index.unique().tolist()\n",
    "        self.DangerousDates = TimeStampCount[TimeStampCount > 10000].index.tolist()\n",
    "        self.FilteredDates = [date for date in self.TrainDates if date not in self.DangerousDates]\n",
    "\n",
    "        self.TrainSet = {}\n",
    "\n",
    "        self.AM = self.Train[self.Train[\"Hour\"] < 11.70]\n",
    "        self.PM = self.Train[self.Train[\"Hour\"] > 12.70]\n",
    "\n",
    "        for date in self.FilteredDates:\n",
    "            self.TrainSet[f\"{date}|AM\"] = self.AM.loc[date]\n",
    "            self.TrainSet[f\"{date}|PM\"] = self.PM.loc[date]\n",
    "\n",
    "        # Splitting Testing Set\n",
    "        self.TestingSet = []\n",
    "\n",
    "        for begin in range(0, len(self.Test), 10):\n",
    "            self.TestingSet.append(self.Test.iloc[begin: begin + 10])\n",
    "\n",
    "    def training_dates(self):\n",
    "        \"\"\"\n",
    "        Returning all training set dates\n",
    "        \"\"\"\n",
    "        return self.FilteredDates\n",
    "\n",
    "    def get_training_numpy(self, idx):\n",
    "        \"\"\"\n",
    "        Returning training set at idx, also the am / pm / date infomation trailing it.\n",
    "        [T, Feature]\n",
    "        \"\"\"\n",
    "        key = list(self.TrainSet.keys())[idx]\n",
    "        pandadb = self.TrainSet[key][self.dataitems]\n",
    "        return key, pandadb.values\n",
    "\n",
    "    def get_testing_numpy(self, idx):\n",
    "        \"\"\"\n",
    "        Returning testing set at idx, also the am / pm / date infomation trailing it.\n",
    "        [T, Feature]\n",
    "        \"\"\"\n",
    "        pandadb = self.TestingSet[idx][self.dataitems]\n",
    "        return pandadb.values\n",
    "\n",
    "    def training_count(self):\n",
    "        \"\"\"\n",
    "        Returning the count of all available sub training set, including morning and afternoon\n",
    "        \"\"\"\n",
    "        return len(self.TrainSet)\n",
    "\n",
    "    def testing_count(self):\n",
    "        \"\"\"\n",
    "        Returning the count of all testing instance\n",
    "        \"\"\"\n",
    "        return len(self.TestingSet) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T21:16:24.687453Z",
     "start_time": "2018-12-28T21:16:22.489236Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    dataitems = [\"BidVolume1\", \"AskVolume1\", \"DiffVolume\", \"DiffBidVolume1\", \"DiffAskVolume1\", \"OneHot&7\"]\n",
    "    def __init__(self, csvreader=CSVReader()):\n",
    "        self.Train = []\n",
    "        self.Test = []\n",
    "\n",
    "        self.reader = csvreader\n",
    "        for idx in range(self.reader.training_count()):\n",
    "            time, npdata = self.reader.get_training_numpy(idx)\n",
    "            self.Train.append(torch.from_numpy(npdata).contiguous().to(device=device, dtype=torch.float32))\n",
    "\n",
    "        for idx in range(self.reader.testing_count()):\n",
    "            npdata = self.reader.get_testing_numpy(idx)\n",
    "            self.Test.append(torch.from_numpy(npdata).contiguous().to(device=device, dtype=torch.float32))\n",
    "\n",
    "        self.valid_idx = []\n",
    "        self.train_idx = [_ for _ in range(0, len(self.Train))]\n",
    "        self.set_validation_set([20, 31, 42, 51])\n",
    "    \n",
    "    def sample_processed_batch(self, batch_size=32, source=\"train\", length=40):\n",
    "        if source == \"train\":\n",
    "            choice = np.random.choice(self.train_idx)\n",
    "        else:\n",
    "            choice = np.random.choice(self.valid_idx)\n",
    "\n",
    "        L = len(self.Train[choice]) # []\n",
    "        IDX = torch.randint(1, L - length - 21, (batch_size,)) # [Batch]\n",
    "        A = self.Train[choice] # [Day Length, Features = 5]\n",
    "        Q = torch.arange(0, length + 21, dtype=torch.long).unsqueeze(0) # [1, L + 21]\n",
    "        P = IDX.unsqueeze(1) # [Batch, 1]\n",
    "        W = A[P + Q] # [Batch, L + 21, Features = 5]\n",
    "        # BEGIN INSERT\n",
    "        \n",
    "        C = torch.arange(1, 21, dtype=torch.long).unsqueeze(0) # [1, 20]\n",
    "        V = torch.arange(0, length, dtype=torch.long).unsqueeze(1) # [L, 1]\n",
    "        B = C + V \n",
    "        T = W[:, B, -1] # [Batch, L, 20]\n",
    "        Target = T.mean(dim=-1) - W[:, :length, -1] # [Batch, L]\n",
    "        \n",
    "        # END INSERT\n",
    "        W = W[:, :-21, :4] # [Batch, L, Features = 4]\n",
    "        M = A[P + Q - 1][:, :-21, :4] # [Batch, L, Features = 4]\n",
    "        \n",
    "        D = W - M\n",
    "        \n",
    "        NormalFeatures = W[:, :, 1:3]\n",
    "        DifferentialFeatures = D[:, :, :3]\n",
    "        DeltaPrice = torch.round(D[:, :, 3: 4] * 1000).to(torch.long) + 3\n",
    "        DeltaPrice[DeltaPrice > 3] = 3\n",
    "        DeltaPrice[DeltaPrice < -3] = -3\n",
    "        eye = torch.eye(7)\n",
    "        DeltaPriceOneHot = eye[DeltaPrice].squeeze(dim=-2)\n",
    "        R = torch.cat([NormalFeatures, DifferentialFeatures, DeltaPriceOneHot], dim=-1)\n",
    "        return R, Target\n",
    "    \n",
    "    def get_test_batch(self, batch_size=8):\n",
    "        # Test sequence are all of length 9, they are all from the valid set.\n",
    "        choice = np.random.choice(self.valid_idx)\n",
    "        \n",
    "        L = len(self.Train[choice])\n",
    "        IDX = torch.randint(1, L - 29, (batch_size,))\n",
    "        A = self.Train[choice]\n",
    "        Q = torch.arange(0, 29, dtype=torch.long).unsqueeze(0)\n",
    "        P = IDX.unsqueeze(1)\n",
    "        W = A[P + Q]\n",
    "        Target = W[:, 9:, -1].mean(dim=-1) - W[:, 9, -1]\n",
    "        M = A[P + Q - 1]\n",
    "        \n",
    "        D = W - M\n",
    "        \n",
    "        NormalFeatures = W[:, :, 1:3]\n",
    "        DifferentialFeatures = D[:, :, :3]\n",
    "        DeltaPrice = torch.round(D[:, :, 3: 4] * 1000).to(torch.long) + 3\n",
    "        DeltaPrice[DeltaPrice > 3] = 3\n",
    "        DeltaPrice[DeltaPrice < -3] = -3\n",
    "        eye = torch.eye(7)\n",
    "        DeltaPriceOneHot = eye[DeltaPrice].squeeze(dim=-2)\n",
    "        R = torch.cat([NormalFeatures, DifferentialFeatures, DeltaPriceOneHot], dim=-1)\n",
    "        return R, Target\n",
    "    \n",
    "    def get_test_batch_from_train(self, batch_size=8):\n",
    "        # Test sequence are all of length 9, they are all from the valid set.\n",
    "        choice = np.random.choice(self.valid_idx)\n",
    "        \n",
    "        L = len(self.Train[choice])\n",
    "        IDX = torch.randint(1, L - 29, (batch_size,))\n",
    "        A = self.Train[choice]\n",
    "        Q = torch.arange(0, 29, dtype=torch.long).unsqueeze(0)\n",
    "        P = IDX.unsqueeze(1)\n",
    "        W = A[P + Q] # [Batch, 29, 4]\n",
    "        Target = W[:, 9:, -1].mean(dim=-1) - W[:, 9, -1]\n",
    "        \n",
    "        M = A[P + Q - 1]\n",
    "        \n",
    "        D = W - M\n",
    "        \n",
    "        NormalFeatures = W[:, :, 1:3]\n",
    "        DifferentialFeatures = D[:, :, :3]\n",
    "        DeltaPrice = torch.round(D[:, :, 3: 4] * 1000).to(torch.long) + 3\n",
    "        DeltaPrice[DeltaPrice > 3] = 3\n",
    "        DeltaPrice[DeltaPrice < -3] = -3\n",
    "        eye = torch.eye(7)\n",
    "        DeltaPriceOneHot = eye[DeltaPrice].squeeze(dim=-2)\n",
    "        R = torch.cat([NormalFeatures, DifferentialFeatures, DeltaPriceOneHot], dim=-1)\n",
    "        return R, Target\n",
    "\n",
    "    def get_train_continuous(self, batch_size=32, length=40):\n",
    "        return self.sample_processed_batch(batch_size, length=length)\n",
    "\n",
    "    def get_valid_continuous(self, batch_size=32, length=40):\n",
    "        return self.sample_processed_batch(batch_size, source=\"valid\", length=length)\n",
    "    \n",
    "    def get_test(self):\n",
    "        # Returns all 1000 testing samples\n",
    "        Test = torch.stack(self.Test, dim=0) # [1000, 10, 5]\n",
    "        W = Test[:, 1:, :]\n",
    "        M = Test[:, :-1, :]\n",
    "        D = W - M\n",
    "        End = Test[:, -1, -1]\n",
    "        \n",
    "        NormalFeatures = W[:, :, 1:3]\n",
    "        DifferentialFeatures = D[:, :, :3]\n",
    "        DeltaPrice = torch.round(D[:, :, 3: 4] * 1000).to(torch.long) + 3\n",
    "        DeltaPrice[DeltaPrice > 3] = 3\n",
    "        DeltaPrice[DeltaPrice < -3] = -3\n",
    "        eye = torch.eye(7)\n",
    "        DeltaPriceOneHot = eye[DeltaPrice].squeeze(dim=-2)\n",
    "        R = torch.cat([NormalFeatures, DifferentialFeatures, DeltaPriceOneHot], dim=-1)\n",
    "        return R, End\n",
    "        \n",
    "    def set_validation_set(self, lst):\n",
    "        self.valid_idx = lst\n",
    "        self.train_idx.clear()\n",
    "        for idx in range(0, len(self.Train)):\n",
    "            if idx not in lst:\n",
    "                self.train_idx.append(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T21:16:25.492760Z",
     "start_time": "2018-12-28T21:16:24.710782Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = DataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T21:16:25.522109Z",
     "start_time": "2018-12-28T21:16:25.511988Z"
    }
   },
   "outputs": [],
   "source": [
    "class Prenet(nn.Module):\n",
    "    def __init__(self, in_channel=12, out_channel=32, kernel_size=2):\n",
    "        super(Prenet, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels=in_channel, out_channels=out_channel, kernel_size=kernel_size, )\n",
    "        self.activation = nn.ReLU()\n",
    "        self.norm = nn.BatchNorm1d(num_features=out_channel)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # [Batch, Length, Features = 12]\n",
    "        return self.activation(\n",
    "            self.norm(\n",
    "                self.conv(x.transpose(-1, -2))\n",
    "            )\n",
    "        ).transpose(-1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T21:16:25.557021Z",
     "start_time": "2018-12-28T21:16:25.546628Z"
    }
   },
   "outputs": [],
   "source": [
    "class Prednet(nn.Module):\n",
    "    def __init__(self, in_channel=32, hidden_size=128, num_layers=1, dropout=0.2):\n",
    "        super(Prednet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size=in_channel, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.outlayer = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.scale = 0.004\n",
    "        self.h = nn.Parameter(torch.zeros(num_layers, 1, hidden_size))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Length - 1, Features = in_channel]\n",
    "        h_0 = self.h.expand(self.num_layers, x.size(0), self.hidden_size).contiguous()\n",
    "        out, h_n = self.rnn(x, h_0) # [Batch, Length - 1, Hidden], [Batch, Hidden]\n",
    "        x = self.activation(out)\n",
    "        x = self.outlayer(x) * self.scale\n",
    "        return x.squeeze(-1) # [Batch, Length - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T21:16:25.589614Z",
     "start_time": "2018-12-28T21:16:25.581693Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, feature_n=12, cnn_channel=32, kernel_size=2, rnn_size=128, rnn_dropout=0.0, num_layers=1):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.prenet = Prenet(in_channel=feature_n, out_channel=cnn_channel, kernel_size=kernel_size)\n",
    "        self.postnet = Prednet(in_channel=cnn_channel, hidden_size=rnn_size, dropout=rnn_dropout, num_layers=num_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.postnet(self.prenet(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T21:16:26.313207Z",
     "start_time": "2018-12-28T21:16:25.612800Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    kernel_size=3\n",
    "    model = RNNModel(\n",
    "        feature_n=12, \n",
    "        cnn_channel=32,\n",
    "        kernel_size=kernel_size, \n",
    "        rnn_size=64,\n",
    "        rnn_dropout=0.5,\n",
    "        num_layers=1\n",
    "    )\n",
    "    \n",
    "    kernel_displacement = kernel_size - 1\n",
    "    \n",
    "    learning_rate = 0.00000000001\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    loader = DataLoader()\n",
    "    \n",
    "    batch_size = 8\n",
    "    \n",
    "    seq_length = 512\n",
    "    \n",
    "    epoch = 1000\n",
    "    \n",
    "    evaluate_epoch = 5\n",
    "    \n",
    "    smoothed_rmse = 0.0015\n",
    "    smoothed_evaluation = 0.0015\n",
    "    def get_train_batch(self):\n",
    "        Feat, Target = self.loader.get_train_continuous(self.batch_size, self.seq_length)\n",
    "        Feat[:, :, :5] = torch.log(1.0 + Feat[:, :, :5].relu()) / 18.0\n",
    "        return Feat, Target[:, self.kernel_displacement:]\n",
    "    \n",
    "    def train_single_batch(self):\n",
    "        Feat, Target = self.get_train_batch()\n",
    "        Estimate = self.model(Feat)\n",
    "        Loss = (Estimate - Target).pow(2).mean().sqrt()\n",
    "        return Loss\n",
    "    \n",
    "    def train(self, lr=learning_rate):\n",
    "        bar = tnrange(self.epoch)\n",
    "        self.optim.lr = lr\n",
    "        for idx in bar:\n",
    "            self.optim.zero_grad()\n",
    "            loss = self.train_single_batch()\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            self.smoothed_rmse = loss.item() * 0.01 + 0.99 * self.smoothed_rmse\n",
    "            self.smoothed_evaluation = self.evaluation() * 0.01 + 0.99 * self.smoothed_rmse\n",
    "            bar.set_postfix(loss=f\"{self.smoothed_rmse:.7f}\", e=f\"{self.smoothed_evaluation:.7f}\")\n",
    "        \n",
    "    def evaluation(self):\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            Feat, Target = self.loader.get_valid_continuous(self.batch_size, self.seq_length)\n",
    "            Feat[:, :, :5] = torch.log(1.0 + Feat[:, :, :5].relu()) / 18.0\n",
    "            Target = Target[:, self.kernel_displacement:]\n",
    "            Estimate = self.model(Feat)\n",
    "            Loss = (Estimate - Target).pow(2).mean().sqrt()\n",
    "            self.model.train()\n",
    "            return Loss.item()\n",
    "    \n",
    "    def test(self):\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            Feat, End = self.loader.get_test()\n",
    "            Feat[:, :, :5] = torch.log(1.0 + Feat[:, :, :5].relu()) / 18.0\n",
    "            Estimate = self.model(Feat)\n",
    "            Estimate = Estimate[:, -1]\n",
    "            self.model.train()\n",
    "            return Estimate.detach().cpu().numpy() + End.cpu().numpy(), Estimate.detach().cpu().numpy() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T21:16:26.355971Z",
     "start_time": "2018-12-28T21:16:26.352031Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate, delta = trainer.test()\n",
    "import pandas as pd\n",
    "ANS = pd.DataFrame(index=np.arange(143, 1001, dtype=int), data=estimate[142:], columns=[\"midprice\"])\n",
    "ANS.index.name = \"caseid\"\n",
    "ANS.to_csv(f\"submit_{np.random.randint(100)}.csv\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
